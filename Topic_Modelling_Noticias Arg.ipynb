{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da6JAL8d3QEh"
      },
      "source": [
        "# Paso 1 - Preparar el ambiente instalando todo lo necesario"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmhFpKHU3JlW",
        "outputId": "fa7e8d4c-446b-4c5b-f4e8-2ba7f192449e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mpld3\n",
            "  Downloading mpld3-0.5.9-py3-none-any.whl (201 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/201.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/201.2 kB\u001b[0m \u001b[31m917.8 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m143.4/201.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.2/201.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mpld3) (3.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mpld3) (3.7.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mpld3) (2.1.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mpld3) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mpld3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mpld3) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mpld3) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mpld3) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mpld3) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mpld3) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mpld3) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mpld3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mpld3) (1.16.0)\n",
            "Installing collected packages: mpld3\n",
            "Successfully installed mpld3-0.5.9\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "try:\n",
        "  from bertopic import BERTopic\n",
        "except:\n",
        "  !pip install bertopic\n",
        "  from bertopic import BERTopic\n",
        "\n",
        "try:\n",
        "  import es_core_news_sm\n",
        "except:\n",
        "  !python -m spacy download es_core_news_sm\n",
        "  import es_core_news_sm\n",
        "\n",
        "try:\n",
        "  import mpld3\n",
        "except:\n",
        "  !pip install mpld3\n",
        "  import mpld3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0klYE31C0jlP"
      },
      "source": [
        "# Paso 2 - Descarga de los files con noticias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhNrQ1F3k6ku",
        "outputId": "13243195-f9f9-4060-b7aa-af7380f1d865"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading https://github.com/fermasia/news-base/blob/main/files/\n"
          ]
        }
      ],
      "source": [
        "def download(months=None,url=None):\n",
        "  '''\n",
        "  Función para recuperar el repositorio en Github una lista de files conteniendo noticias por mes y año\n",
        "  '''\n",
        "  files = {}\n",
        "  for m in months:\n",
        "      try:\n",
        "          data_url = url + m + '.csv.gz?raw=true'\n",
        "          files[m] = pd.read_csv(data_url, compression='gzip')\n",
        "          print('downloading',url)\n",
        "      except:\n",
        "          months.remove(m)\n",
        "\n",
        "  df = pd.concat(files.values(), ignore_index=True)\n",
        "  # Descartar categoría sobredimensionada para uno de los diarios\n",
        "  df = df[df.category != 'mundo']\n",
        "  return df\n",
        "\n",
        "months = ['202306','202307','202308'] # '202301','202302','202303','202304','202305'\n",
        "url = 'https://github.com/fermasia/news-base/blob/main/files/'\n",
        "news_df = download( months = months , url = url )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G776HzbO0tgg"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Paso 3 - Preparación del Dataset y Visualizaciones iniciales"
      ],
      "metadata": {
        "id": "USSSUcHhwEnu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXmAToAVk6d_"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(df):\n",
        "  '''\n",
        "  Función para realizar las preparaciones iniciales del dataset, agregar\n",
        "  una columna con mes y año en base a una fecha\n",
        "  '''\n",
        "  print('Preparing dataset'\n",
        "  #m = 3\n",
        "  ### Force datetime format\n",
        "  df['date'] = pd.to_datetime(df['date'], errors='coerce', utc=True).dt.tz_convert('America/Argentina/Buenos_Aires')\n",
        "  # Discard records before 2021/12/1\n",
        "  df = df[df['date'] > '2021-11-30']\n",
        "  # Create yyyymm field\n",
        "  df['yyyymm'] = df['date'].dt.year.astype(str) + '-' + df['date'].dt.month.astype(str).str.zfill(2)\n",
        "\n",
        "  # Order rows by source and yyyymm and reset indexes\n",
        "  df.sort_values(by=['yyyymm','source'],ascending=True,inplace=True)\n",
        "  df.reset_index(drop=True,inplace=True)\n",
        "\n",
        "  # Make sure we are only keeping the months received as parameter\n",
        "  m = [ x[:4] + '-' + str(int(x[-2:])*1).zfill(2) for x in months ]\n",
        "  df = df[df.yyyymm.isin(m)]\n",
        "  return df\n",
        "\n",
        "prepared_df = prepare_dataset(news_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p51NhaDw759R"
      },
      "outputs": [],
      "source": [
        "temp = prepared_df[prepared_df.category.isin(['politica','economia','sociedad','deportes'])].groupby(['yyyymm','source']).count()['text'].reset_index()\n",
        "\n",
        "def create_pivot_table(df, rows, columns, values):\n",
        "    pivot_table = df.pivot_table(index=rows, columns=columns, values=values)\n",
        "    return pivot_table\n",
        "\n",
        "temp\n",
        "\n",
        "create_pivot_table(temp, 'yyyymm' , 'source', 'text').fillna(0).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpUJtsljgHB2"
      },
      "outputs": [],
      "source": [
        "prepared_df[prepared_df.category == 'politica'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqnJId2eDDD0"
      },
      "outputs": [],
      "source": [
        "temp = prepared_df[prepared_df.category.isin(['politica','economia','sociedad','deportes'])].groupby(['yyyymm','category']).count()['text'].reset_index()\n",
        "\n",
        "def create_pivot_table(df, rows, columns, values):\n",
        "    pivot_table = df.pivot_table(index=rows, columns=columns, values=values)\n",
        "    return pivot_table\n",
        "\n",
        "temp\n",
        "\n",
        "create_pivot_table(temp, 'yyyymm' , 'category', 'text').fillna(0).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sdwvysc8Dyai"
      },
      "outputs": [],
      "source": [
        "temp = prepared_df.groupby(['category','source']).count()['text'].reset_index()\n",
        "\n",
        "def create_pivot_table(df, rows, columns, values):\n",
        "    pivot_table = df.pivot_table(index=rows, columns=columns, values=values)\n",
        "    return pivot_table\n",
        "\n",
        "temp\n",
        "\n",
        "create_pivot_table(temp, 'category' , 'source', 'text').fillna(0).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egLCqxtjk6Yq"
      },
      "outputs": [],
      "source": [
        "def plot_summary(df):\n",
        "    for sect in df.category.unique():\n",
        "        # Group the data by \"yyyym\" and \"source\" and count the number of news articles for each combination\n",
        "        df_grouped = df[df.category == sect].groupby(['yyyymm', 'source']).size().unstack().fillna(0)\n",
        "        # Create an unstacked bar plot\n",
        "        df_grouped.plot(kind='bar', stacked=False, figsize=(10, 3), color=['#EB172B', '#F68E1E', '#006998', '#32937f'])\n",
        "        # Set the labels in Spanish\n",
        "        plt.xlabel('Año-Mes')\n",
        "        title = 'Noticias por Mes y Periódico - Sección: ' + str(sect).capitalize()\n",
        "        plt.ylabel('N# Artículos')\n",
        "        plt.title(title)\n",
        "        plt.legend(title='Periódico', loc='upper right')\n",
        "        plt.legend(bbox_to_anchor=(1.02, 1.0), loc='upper left')\n",
        "        plt.xticks(rotation=0)  # Set x-axis labels horizontal\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "plot_summary(prepared_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVDbhlsWyHd3"
      },
      "outputs": [],
      "source": [
        "section = 'politica'\n",
        "content = 'title' # title, text, all\n",
        "\n",
        "def create_corpus_df(df):\n",
        "  print('Creating corpus')\n",
        "  # Si se definió una sección, filtrar\n",
        "  if section == '':\n",
        "      corpus_df = df.copy()\n",
        "  else:\n",
        "      corpus_df = df[df.category == section].reset_index(drop=True)\n",
        "\n",
        "  # Concatenar medio y mes-año\n",
        "  corpus_df['source'] = corpus_df['yyyymm'] + '_' + corpus_df['source']\n",
        "\n",
        "  # conservamos los origenes y el mes año para unir luego de procesar\n",
        "  links_df = corpus_df['link']\n",
        "  sources_df = corpus_df['source']\n",
        "  dates_df = corpus_df['date']\n",
        "\n",
        "  # Según se haya definido, filtrar Titulo, Cuerpo o concatenar todo\n",
        "  if  content == 'title':\n",
        "      corpus_df = pd.DataFrame(corpus_df.title)\n",
        "      col = 'title'\n",
        "\n",
        "  elif content == 'text':\n",
        "      corpus_df = pd.DataFrame(corpus_df.text)\n",
        "      col = 'text'\n",
        "  else:\n",
        "      corpus_df = pd.DataFrame(corpus_df.title + ' ' + corpus_df.text)\n",
        "      col = 0\n",
        "\n",
        "  # Renombrar columna y asegurar que sea STR\n",
        "  corpus_df.rename(columns={col:'text'},inplace=True)\n",
        "  corpus_df['text'] = corpus_df.text.astype(str)\n",
        "\n",
        "  # Store list of timestamps to reuse later\n",
        "  timestamp = dates_df.to_list()\n",
        "\n",
        "  return corpus_df, sources_df, dates_df, links_df\n",
        "\n",
        "corpus_df, sources_df, dates_df, links_df = create_corpus_df(prepared_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXiNRhW0k6T2"
      },
      "outputs": [],
      "source": [
        "def solve_capital_middle(sentence):\n",
        "    words = sentence.split()\n",
        "    modified_sentence = []\n",
        "\n",
        "    for word in words:\n",
        "        for i in range(1, len(word) - 1):  # Check from the second character to the second-to-last character\n",
        "            if word[i].isupper():\n",
        "                split_words = [word[:i] + '.', word[i:]]\n",
        "                modified_sentence.extend(split_words)\n",
        "                break\n",
        "        else:\n",
        "            modified_sentence.append(word)\n",
        "\n",
        "    return ' '.join(modified_sentence)\n",
        "\n",
        "def clean_text(text):\n",
        "    # Replace HTML tags with a space\n",
        "    cleaned_text = re.sub(r'<[^>]+>', ' ', text)\n",
        "\n",
        "    # Define a set of characters to replace with spaces\n",
        "    replace_chars = \"@#^&*()!\\\"'<>/-_\"  # Add any additional characters here if needed\n",
        "\n",
        "    # Replace specified characters with spaces\n",
        "    for char in replace_chars:\n",
        "        cleaned_text = cleaned_text.replace(char, ' ')\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "def clean_corpus_df(df):\n",
        "  print('Cleaning Corpus')\n",
        "  df['text'] = df['text'].apply(solve_capital_middle)\n",
        "  df['text'] = df['text'].apply(clean_text)\n",
        "\n",
        "  return df\n",
        "\n",
        "cleaned_df = clean_corpus_df(corpus_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAmLpFV30j5n"
      },
      "outputs": [],
      "source": [
        "def build_final_dataset_df(list_df):\n",
        "  print('Building Final Dataset')\n",
        "  return pd.concat( list_df , axis='columns')\n",
        "\n",
        "final_df = build_final_dataset_df( [cleaned_df, sources_df , dates_df, links_df] )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paso 4 - Modelado\n"
      ],
      "metadata": {
        "id": "v4Han2rSwbWo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xHv6oLCk6WP"
      },
      "outputs": [],
      "source": [
        "def make_embeddings(df_field):\n",
        "  from sentence_transformers import SentenceTransformer\n",
        "  # Prepare embeddings\n",
        "  sentence_model = SentenceTransformer(\"distiluse-base-multilingual-cased-v1\")\n",
        "  embeddings = sentence_model.encode(df_field, show_progress_bar=True)\n",
        "  # Train our topic model using our pre-trained sentence-transformers embeddings\n",
        "  return embeddings\n",
        "\n",
        "embeddings = make_embeddings(final_df['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4IhtJHfTbej"
      },
      "outputs": [],
      "source": [
        "#!python -m spacy download es_core_news_sm\n",
        "import es_core_news_sm\n",
        "from bertopic.representation import PartOfSpeech\n",
        "from bertopic.representation import MaximalMarginalRelevance\n",
        "\n",
        "parts_of_speech = PartOfSpeech(\"es_core_news_sm\")\n",
        "mmr = MaximalMarginalRelevance(diversity=0.3)\n",
        "representation_models = [mmr, parts_of_speech]\n",
        "\n",
        "from umap import UMAP\n",
        "#umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.5, metric='cosine', random_state=912)\n",
        "umap_model = UMAP(random_state=912)\n",
        "from hdbscan import HDBSCAN\n",
        "#hdbscan_model = HDBSCAN(min_cluster_size=150, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "stopwords_es = pd.read_csv('https://raw.githubusercontent.com/jbagnato/machine-learning/master/nlp/spanish.txt',header=None)[0].to_list()\n",
        "vectorizer_model = CountVectorizer(stop_words=stopwords_es, min_df=2, ngram_range=(1, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3E2RgvSeVxv_"
      },
      "outputs": [],
      "source": [
        "topic_model = BERTopic(language=\"multilingual\",\n",
        "                      representation_model = representation_models,\n",
        "                      umap_model=umap_model,\n",
        "                      vectorizer_model=vectorizer_model,\n",
        "                      calculate_probabilities=True,\n",
        "                      nr_topics= \"auto\")\n",
        "topics, probs = topic_model.fit_transform(final_df.text.to_list(),embeddings)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paso 5 - Visualización de los resultados"
      ],
      "metadata": {
        "id": "9REy-FY-winu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUACf3MDh7qH"
      },
      "outputs": [],
      "source": [
        "fig = topic_model.visualize_barchart(top_n_topics=30)\n",
        "fig.write_html(\"top30_topics.html\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1WEcdAdVxzN"
      },
      "outputs": [],
      "source": [
        "def plot_bars(df,q,figsize,save=False):\n",
        "    tabla = df[df.category == section].reset_index(drop=True)\n",
        "    labels = pd.DataFrame()\n",
        "    labels['num'] = pd.DataFrame(topic_model.generate_topic_labels()[1:])[0].str.split('_').apply(lambda x: x[0])\n",
        "    labels['tema'] = pd.DataFrame(topic_model.generate_topic_labels()[1:])[0].str.split('_').apply(lambda x: \"-\".join(x[1:]))\n",
        "    labels['num'] = labels['num'].astype(str)\n",
        "    temas = pd.DataFrame(pd.DataFrame(probs).idxmax(axis=1)).rename({0:'num'},axis=1)\n",
        "    temas['num'] = temas['num'].astype(str)\n",
        "    temas = pd.merge(temas,labels,on='num',how='left')['tema']\n",
        "    tabla = pd.merge(tabla,temas,left_index=True, right_index=True)\n",
        "\n",
        "    agrupado = tabla.groupby(['source','tema','yyyymm']).count()['text'].reset_index().rename({'text':'porc'},axis=1)\n",
        "    agrupado['porc'] /= agrupado.groupby(['source','yyyymm'])['porc'].transform('max').div(100)\n",
        "    agrupado['porc'] = agrupado.porc.round(2)\n",
        "\n",
        "    top = tabla.groupby(['tema']).count()['source'].reset_index().sort_values(by='source',ascending=False).head(q)['tema'].to_list()\n",
        "\n",
        "    from matplotlib import pyplot as plt\n",
        "    for pos, tema in enumerate(top):\n",
        "        final = agrupado[agrupado.tema == tema ].drop(columns=['tema'])\n",
        "        if save:\n",
        "          name = 'plo_'+ section + '_' + str(pos) + '.png'\n",
        "          final.pivot('yyyymm','source','porc').plot.bar(figsize=figsize,title=tema,alpha=0.9,rot=0,color=['#EB172B', '#F68E1E', '#006998', '#32937f'],xlabel='').get_figure().savefig(name)\n",
        "          print(name,'stored')\n",
        "        else:\n",
        "          final.pivot('yyyymm','source','porc').plot.bar(figsize=figsize,title=tema,alpha=0.9,rot=0,color=['#EB172B', '#F68E1E', '#006998', '#32937f'],xlabel='')\n",
        "\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def plot_bars2(df, q, section, figsize, save=False):\n",
        "    tabla = df[df.category == section].reset_index(drop=True)\n",
        "    labels = pd.DataFrame()\n",
        "    labels['num'] = pd.DataFrame(topic_model.generate_topic_labels()[1:])[0].str.split('_').apply(lambda x: x[0])\n",
        "    labels['tema'] = pd.DataFrame(topic_model.generate_topic_labels()[1:])[0].str.split('_').apply(lambda x: \"-\".join(x[1:]))\n",
        "    labels['num'] = labels['num'].astype(str)\n",
        "    temas = pd.DataFrame(pd.DataFrame(probs).idxmax(axis=1)).rename({0: 'num'}, axis=1)\n",
        "    temas['num'] = temas['num'].astype(str)\n",
        "    temas = pd.merge(temas, labels, on='num', how='left')['tema']\n",
        "    tabla = pd.merge(tabla, temas, left_index=True, right_index=True)\n",
        "\n",
        "    agrupado = tabla.groupby(['source', 'tema', 'yyyymm']).count()['text'].reset_index().rename({'text': 'porc'}, axis=1)\n",
        "    agrupado['porc'] /= agrupado.groupby(['source', 'yyyymm'])['porc'].transform('max').div(100)\n",
        "    agrupado['porc'] = agrupado.porc.round(2)\n",
        "\n",
        "    top = tabla.groupby(['tema']).count()['source'].reset_index().sort_values(by='source', ascending=False).head(q)['tema'].to_list()\n",
        "\n",
        "    for pos, tema in enumerate(top):\n",
        "        final = agrupado[agrupado.tema == tema].drop(columns=['tema'])\n",
        "        if save:\n",
        "            name = 'plo_' + section + '_' + str(pos) + '.png'\n",
        "            ax = final.pivot('yyyymm', 'source', 'porc').plot.bar(\n",
        "                figsize=figsize,\n",
        "                title=tema,\n",
        "                alpha=0.7,\n",
        "                rot=0,\n",
        "                color=['#EB172B', '#F68E1E', '#006998', '#32937f'],\n",
        "                xlabel=''\n",
        "            )\n",
        "            plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))  # Place legend outside the plot space\n",
        "            for container in ax.containers:\n",
        "                plt.setp(container, alpha=0.7)  # Set transparency to the bars\n",
        "            plt.savefig(name, bbox_inches='tight')  # Save the plot with adjusted legend position\n",
        "            print(name, 'stored')\n",
        "        else:\n",
        "            final.pivot('yyyymm', 'source', 'porc').plot.bar(\n",
        "                figsize=figsize,\n",
        "                title=tema,\n",
        "                alpha=0.9,\n",
        "                rot=0,\n",
        "                color=['#EB172B', '#F68E1E', '#006998', '#32937f'],\n",
        "                xlabel=''\n",
        "            )\n",
        "            plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))  # Place legend outside the plot space\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import mpld3\n",
        "\n",
        "def plot_bars3(df, q, section, figsize, save=False):\n",
        "    tabla = df[df.category == section].reset_index(drop=True)\n",
        "    labels = pd.DataFrame()\n",
        "    labels['num'] = pd.DataFrame(topic_model.generate_topic_labels()[1:])[0].str.split('_').apply(lambda x: x[0])\n",
        "    labels['tema'] = pd.DataFrame(topic_model.generate_topic_labels()[1:])[0].str.split('_').apply(lambda x: \"-\".join(x[1:]))\n",
        "    labels['num'] = labels['num'].astype(str)\n",
        "    temas = pd.DataFrame(pd.DataFrame(probs).idxmax(axis=1)).rename({0: 'num'}, axis=1)\n",
        "    temas['num'] = temas['num'].astype(str)\n",
        "    temas = pd.merge(temas, labels, on='num', how='left')['tema']\n",
        "    tabla = pd.merge(tabla, temas, left_index=True, right_index=True)\n",
        "\n",
        "    agrupado = tabla.groupby(['source', 'tema', 'yyyymm']).count()['text'].reset_index().rename({'text': 'porc'}, axis=1)\n",
        "    agrupado['porc'] /= agrupado.groupby(['source', 'yyyymm'])['porc'].transform('max').div(100)\n",
        "    agrupado['porc'] = agrupado.porc.round(2)\n",
        "\n",
        "    top = tabla.groupby(['tema']).count()['source'].reset_index().sort_values(by='source', ascending=False).head(q)['tema'].to_list()\n",
        "\n",
        "    num_plots = len(top)\n",
        "    rows = (num_plots + 1) // 2  # Calculate number of rows for the subplot grid\n",
        "    fig, axes = plt.subplots(rows, 2, figsize=(figsize[0]*2, figsize[1]*rows))  # Create subplot grid\n",
        "\n",
        "    html_plots = []  # To store HTML representations of the plots\n",
        "\n",
        "    for pos, tema in enumerate(top):\n",
        "        final = agrupado[agrupado.tema == tema].drop(columns=['tema'])\n",
        "        current_ax = axes[pos // 2, pos % 2] if rows > 1 else axes[pos % 2]  # Select subplot for the current plot\n",
        "        if save:\n",
        "            name = 'plo_' + section + '_' + str(pos) + '.png'\n",
        "            final.pivot('yyyymm', 'source', 'porc').plot.bar(\n",
        "                ax=current_ax,\n",
        "                alpha=0.7,\n",
        "                rot=0,\n",
        "                color=['#EB172B', '#F68E1E', '#006998', '#32937f'],\n",
        "                legend=False,\n",
        "                xlabel='',\n",
        "                title=tema\n",
        "            )\n",
        "            current_ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))  # Place legend outside the plot space\n",
        "            for container in current_ax.containers:\n",
        "                plt.setp(container, alpha=0.7)  # Set transparency to the bars\n",
        "            plt.savefig(name, bbox_inches='tight')  # Save the plot with adjusted legend position\n",
        "            html_plots.append(mpld3.fig_to_html(fig))\n",
        "            print(name, 'stored')\n",
        "\n",
        "        else:\n",
        "            final.pivot('yyyymm', 'source', 'porc').plot.bar(\n",
        "                ax=current_ax,\n",
        "                alpha=0.9,\n",
        "                rot=0,\n",
        "                color=['#EB172B', '#F68E1E', '#006998', '#32937f'],\n",
        "                legend=False,\n",
        "                xlabel='',\n",
        "                title=tema\n",
        "            )\n",
        "            current_ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))  # Place legend outside the plot space\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save:\n",
        "        with open('plots.html', 'w') as f:\n",
        "            for plot in html_plots:\n",
        "                f.write(plot)  # Write HTML representations of plots to a file\n",
        "    else:\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4aJPpBPk6MU"
      },
      "outputs": [],
      "source": [
        "plot_bars3(prepared_df,q=30, section=section, figsize=(5,1.5),save=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfKUjpFB7nNx"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def plot_topics_over_time(topic_model, final_dataset, timestamp, bins, number_of_topics=10, save=False):\n",
        "    # Calculate topics over time\n",
        "    ovt_df = topic_model.topics_over_time(\n",
        "        final_dataset.text.to_list(),\n",
        "        pd.to_datetime(pd.to_datetime(timestamp)),\n",
        "        nr_bins=bins\n",
        "    )\n",
        "\n",
        "    # Filter topics based on frequency\n",
        "    filtered_topics = filter_classes_within_devest(ovt_df, 'Topic', 'Frequency', 2)\n",
        "    ovt_df = ovt_df[ovt_df.Topic.isin(filtered_topics)]\n",
        "\n",
        "    # Filter topics based on the number_of_topics\n",
        "    ovt_df = ovt_df[ovt_df.Topic.isin(np.arange(0, number_of_topics))]\n",
        "\n",
        "    # Get topic names\n",
        "    topic_names = topic_model.get_topic_info()[['Topic', 'Name']]\n",
        "\n",
        "    # Merge topic names with ovt_df\n",
        "    ovt_df = pd.merge(ovt_df, topic_names, how='left', left_on='Topic', right_on='Topic')\n",
        "\n",
        "    # Convert Timestamp to date\n",
        "    ovt_df['Timestamp'] = pd.to_datetime(ovt_df['Timestamp']).dt.date\n",
        "\n",
        "    # Create a line plot with modifications\n",
        "    fig = px.line(\n",
        "        ovt_df,\n",
        "        x=\"Timestamp\",\n",
        "        y=\"Frequency\",\n",
        "        color='Name',\n",
        "        hover_name=None,\n",
        "        hover_data=[\"Timestamp\", \"Frequency\", \"Words\"]\n",
        "    )\n",
        "\n",
        "    # Adjust line thickness and transparency\n",
        "    fig.update_traces(line=dict(width=4, opacity=0.7))\n",
        "\n",
        "    # Use a pastel palette with divergent colors\n",
        "    fig.update_layout(colorway=['#FFB6C1', '#87CEEB', '#FFD700', '#7FFFD4', '#FFA07A', '#ADD8E6'])\n",
        "\n",
        "    # Set background color to soft grey for visibility\n",
        "    fig.update_layout({\n",
        "        'plot_bgcolor': 'rgba(240, 240, 240, 0.7)',\n",
        "        'paper_bgcolor': 'rgba(240, 240, 240, 0.7)'\n",
        "    })\n",
        "\n",
        "    if save:\n",
        "        # Save the plot as an HTML file\n",
        "        name = 'ovt_' + section + '.html'\n",
        "        fig.write_html(name)\n",
        "        print(name, 'stored')\n",
        "    else:\n",
        "        # Show the plot\n",
        "        fig.show()\n",
        "\n",
        "# Example usage:\n",
        "# plot_topics_over_time(your_topic_model, your_final_dataset, your_timestamp, your_bins, number_of_topics=10, save=False)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmoD676PrgkB"
      },
      "outputs": [],
      "source": [
        "  def filter_classes_within_devest(dataframe,classname,quantity,num_deviations):\n",
        "    # Calculate the mean and standard deviation of the quantity column\n",
        "    mean_quantity = dataframe[quantity].mean()\n",
        "    std_quantity = dataframe[quantity].std()\n",
        "\n",
        "    # Define a threshold for inclusion (n standard deviations from the mean)\n",
        "    threshold = num_deviations * std_quantity\n",
        "\n",
        "    # Filter the DataFrame based on the threshold\n",
        "    filtered_df = dataframe[abs(dataframe[quantity] - mean_quantity) <= threshold]\n",
        "\n",
        "    # Get the list of class names that meet the criteria\n",
        "    class_names = filtered_df[classname].unique()\n",
        "\n",
        "    return class_names\n",
        "\n",
        "def plot_topics_over_time(topic_model, final_dataset, timestamp, bins, number_of_topics=10, save=False):\n",
        "      # Calculate topics over time\n",
        "      ovt_df = topic_model.topics_over_time(\n",
        "          final_dataset.text.to_list(),\n",
        "          pd.to_datetime(pd.to_datetime(timestamp)),\n",
        "          nr_bins=bins\n",
        "      )\n",
        "\n",
        "      # Filter topics based on frequency\n",
        "      filtered_topics = filter_classes_within_devest(ovt_df, 'Topic', 'Frequency', 2)\n",
        "      ovt_df = ovt_df[ovt_df.Topic.isin(filtered_topics)]\n",
        "\n",
        "      # Filter topics based on the number_of_topics\n",
        "      ovt_df = ovt_df[ovt_df.Topic.isin(np.arange(0, number_of_topics))]\n",
        "\n",
        "      # Get topic names\n",
        "      topic_names = topic_model.get_topic_info()[['Topic', 'Name']]\n",
        "\n",
        "      # Merge topic names with ovt_df\n",
        "      ovt_df = pd.merge(ovt_df, topic_names, how='left', left_on='Topic', right_on='Topic')\n",
        "\n",
        "      # Convert Timestamp to date\n",
        "      ovt_df['Timestamp'] = pd.to_datetime(ovt_df['Timestamp']).dt.date\n",
        "\n",
        "      # Create a line plot\n",
        "      fig = px.line(\n",
        "          ovt_df,\n",
        "          x=\"Timestamp\",\n",
        "          y=\"Frequency\",\n",
        "          color='Name',\n",
        "          hover_name=None,\n",
        "          hover_data=[\"Timestamp\", \"Frequency\", \"Words\"]\n",
        "      )\n",
        "\n",
        "      if save:\n",
        "          # Save the plot as an HTML file\n",
        "          name = 'ovt_' + section + '.html'\n",
        "          fig.write_html(name)\n",
        "          print(name, 'stored')\n",
        "      else:\n",
        "          # Show the plot\n",
        "          fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zT_mxINrggy"
      },
      "outputs": [],
      "source": [
        "plot_topics_over_time(topic_model, final_df, dates_df, bins=12, number_of_topics=10, save=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "I6nd__2-B569"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from bertopic import BERTopic\n",
        "from umap import UMAP\n",
        "\n",
        "# # Prepare embeddings\n",
        "# docs = final_df.text.to_list()\n",
        "# sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# topic_model.visualize_documents(docs, embeddings=embeddings)\n",
        "\n",
        "# Reduce dimensionality of embeddings, this step is optional but much faster to perform iteratively:\n",
        "reduced_embeddings = UMAP(n_neighbors=10, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)\n",
        "topic_model.visualize_documents(final_df.text.to_list(), reduced_embeddings=reduced_embeddings)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}